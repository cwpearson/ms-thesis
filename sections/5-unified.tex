\chapter{Unified Memory Performance}
\label{ch:unified}

The unified memory system (Sections~\ref{sec:unified-cc3} and \ref{sec:unified-cc6}) greatly simplifies the programmer interaction with CUDA memories and data transfer.
Data tranfers in the unified memory system are created in two ways:
\begin{itemize}
	\item \textit{coherence} (or \textit{demand}) transfers, where data is migrated to ensure that the CPU and GPU have a consistent view of memory.
	\item \textit{prefetch} transfers, where data is moved ahead of time, with the purpose of reducing future access times. 
\end{itemize}
This chapter comprises two sections, detailing performance of prefetch and coherence unified memory bandwidth (Section~\ref{sec:um-coherence-prefetch}), and page fault latency (Section~\ref{sec:um-page-fault}).
In each section, transfer bandwidth for coherence and prefetch transfers is examined, as well as page-fault latency for demand transfers, where applicable.

Algorithm~\ref{alg:um-bw-gpu-gpu} describes the approach to measure coherence or prefetch bandwidth between two GPUs in the unified memory system.
First, a $bytes$-size unified memory allocation at $ptr$ is associated with the destination device.
As of the time of this writing, this choice of association should not affect the benchmark, but is enforced for consistency.
Then, \texttt{memset} is used to force pages backing the allocation to be produced.
A $start$ and $stop$ event is created on the destination device, where the kernel will be executed for coherence bandwidth measurements.
During the benchmark loop, $ptr$ is prefetch to the source device.
Then, for coherence bandwidth, \texttt{gpu\_write} is executed on the destination device, or for prefetch bandwidth, \texttt{cudaMemPrefetchAsync} is used to prefetch $ptr$ to the destination device.
\texttt{cudaEventSyncrhonize} is used to ensure the coherence or prefetch workload is complete.
The time for the CPU workload or GPU workload and synchronization is recorded as the iteration time.
The benchmark is repeated five times to discover outliers and establish a standard deviation of measurement.

\begin{algorithm}[H]
	\caption[Measuring GPU-GPU Unified Memory Coherence or Prefetch Bandwidth.]{
		Measuring GPU-GPU unified memory coherence or prefetch bandwidth during a $bytes$-sized transfer between $src$ and $dst$.
		\texttt{gpu\_write} is defined in Listing~\ref{lst:gpu-write}.
	}
	\label{alg:um-bw-gpu-gpu}
	\begin{algorithmic}[1]
		\Statex
		\Function{Bandwidth}{$dst$, $src$, $bytes$}
		
		\State $pageSize \gets$ sysconf(\_SC\_PAGESIZE)
		\State cudaSetDevice($dst$)
		\State $ptr \gets$ \texttt{cudaMallocManaged($bytes$)}
		\State \texttt{memset($ptr$, 0, $bytes$)} \Comment force pages to be allocated

		\State cudaEventCreate($start$)
		\State cudaEventCreate($stop$)		        
				
		\For{$state$}
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$) \Comment move pages to $src$
			\State cudaSetDevice($src$)
			\State cudaDeviceSynchronize()
			\State cudaSetDevice($dst$)
			\State cudaDeviceSynchronize()
			\State cudaEventRecord($start$)
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$) \Comment if prefetch, or...
			\State \texttt{gpu\_write<<<$256$,$256$>>>($ptr$, $bytes$, $pageSize$)} \Comment if coherence
			\State cudaEeventRecord($stop$)
			\State cudaEventSynchronize($stop$)
			\State $millis \gets$ cudaEventElapsedTime($start$, $stop$)
			\State state.SetIterationTime($\frac{millis}{1000}$)
		\EndFor
		\EndFunction			
	\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:um-bw-cpu-gpu} describes the approach to measure coherence or prefetch bandwidth from a CPU to a GPU in the unified memory system.
First, execution is bound to the source NUMA node.
Then, the destination CUDA device is set to be active, a $bytes$-sized unified memory allocation is created, and \texttt{cudaMemset} is used to ensure that pages for the allocation are created.
During the event loop, \texttt{cudaMemPrefetchAsync} followed by \texttt{cudaDeviceSynchronize} ensure that unified memory pages are on the source CPU.
Then, the \texttt{gpu\_write} (Listing~\ref{lst:gpu-write}) is used to generate coherence requests to move pages to the destination GPU, or \texttt{cudaMemPrefetchAsync} is used to prefetch pages to the destination GPU.
CUDA events are used to record the elapsed time, and that is used as the benchmark iteration time.
The benchmark is repeated five times to discover outliers and establish a standard deviation of measurement.

\begin{algorithm}[H]
	\caption[Measuring CPU-GPU Unified Memory Coherence or Prefetch Bandwidth.]{
		Measuring CPU-GPU unified memory coherence or prefetch bandwidth during a $bytes$-sized transfer between $src$ and $dst$.
		\texttt{gpu\_write} is defined in Listing~\ref{lst:gpu-write}.
	}
	\label{alg:um-bw-cpu-gpu}
	\begin{algorithmic}[1]
		\Statex
		\Function{Bandwidth}{$dst$, $src$, $bytes$}
		
		\State numa\_bind\_node($src$)
		\State cudaSetDevice($dst$)

		\State $ptr \gets$ \texttt{cudaMallocManaged($bytes$)}
		\State \texttt{cudaMemset($ptr$, 0, $bytes$)} \Comment force pages to be allocated

		\State $pageSize \gets$ sysconf(\_SC\_PAGESIZE)
		\State cudaSetDevice($dst$)

		\State cudaEventCreate($start$)
		\State cudaEventCreate($stop$)		        
				
		\For{$state$}
			\State cudaMemPrefetchAsync($ptr$, $bytes$, cudaCpuDeviceId) \Comment move pages to CPU
			\State cudaDeviceSynchronize()
			\State cudaEventRecord($start$)
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$) \Comment if prefetch, or...
			\State \texttt{gpu\_write<<<$256$,$256$>>>($ptr$, $bytes$, $pageSize$)} \Comment if coherence
			\State cudaEventRecord($stop$)
			\State cudaEventSynchronize($stop$)
			\State $millis \gets$ cudaEventElapsedTime($start$, $stop$)
			\State state.SetIterationTime($\frac{millis}{1000}$)
		\EndFor
		\EndFunction			
	\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:um-coherence-bw-gpu-cpu} describes the approach to measure coherence bandwidth from a GPU to a CPU in the unified memory system.
First, execution is bound to the destination NUMA node.
Then, the source CUDA device is set to be active, a $bytes$-sized unified memory allocation is created, and \texttt{cudaMemset} is used to ensure that pages for the allocation are created.
During the event loop, \texttt{cudaMemPrefetchAsync} followed by \texttt{cudaDeviceSynchronize} ensure that unified memory pages are on the source GPU.
Then, the \texttt{cpu\_write} (Listing~\ref{lst:gpu-write}) is used to generate coherence requests to move pages to the destination CPU.
The automatic benchmark timing may be used instead of CUDA events, as the CPU accesses are guaranteed to complete from the perspective of the CPU just like normal memory accesses.
The benchmark is repeated five times to discover outliers and establish a standard deviation of measurement.

\begin{algorithm}[H]
	\caption[Measuring GPU-to-CPU Unified Memory Coherence Bandwidth.]{
		Measuring GPU-to-CPU unified memory coherence bandwidth during a $bytes$-sized transfer between $src$ and $dst$.
		\texttt{cpu\_write} is defined in Listing~\ref{lst:cpu-write}.
	}
	\label{alg:um-coherence-bw-gpu-cpu}
	\begin{algorithmic}[1]
		\Statex
		\Function{Bandwidth}{$dst$, $src$, $bytes$}
		
		\State numa\_bind\_node($dst$)
		\State cudaSetDevice($src$)

		\State $ptr \gets$ \texttt{cudaMallocManaged($bytes$)}
		\State \texttt{cudaMemset($ptr$, 0, $bytes$)} \Comment force pages to be allocated

		\State $pageSize \gets$ sysconf(\_SC\_PAGESIZE)
		\State cudaSetDevice($dst$)        
				
		\For{$state$}
			\State state.PauseTiming()
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$)
			\State cudaDeviceSynchronize()
			\State state.ResumeTiming()
			\State cpu\_write($ptr$, $bytes$, $pageSize$)
		\EndFor
		\EndFunction			
	\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:um-prefetch-bw-gpu-cpu} describes the approach to measure coherence bandwidth from a GPU to a CPU in the unified memory system.
It is the same as Algorithm~\ref{alg:um-coherence-bw-gpu-cpu}, except CUDA events are used to time the asynchronous \texttt{cudaMemPrefetchAsync} workload.
The benchmark is repeated five times to discover outliers and establish a standard deviation of measurement.

\begin{algorithm}[H]
	\caption[Measuring GPU-to-CPU Unified Memory Prefetch Bandwidth.]{
		Measuring GPU-to-CPU unified memory prefetch bandwidth during a $bytes$-sized transfer between $src$ and $dst$.
		\texttt{cpu\_write} is defined in Listing~\ref{lst:cpu-write}.
	}
	\label{alg:um-prefetch-bw-gpu-cpu}
	\begin{algorithmic}[1]
		\Statex
		\Function{Bandwidth}{$dst$, $src$, $bytes$}
		
		\State numa\_bind\_node($dst$)
		\State cudaSetDevice($src$)

		\State $ptr \gets$ \texttt{cudaMallocManaged($bytes$)}
		\State \texttt{cudaMemset($ptr$, 0, $bytes$)} \Comment force pages to be allocated

		\State $pageSize \gets$ sysconf(\_SC\_PAGESIZE)
		\State cudaSetDevice($dst$)

		\State cudaEventCreate($start$)
		\State cudaEventCreate($stop$)		        
				
		\For{$state$}
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$)
			\State cudaDeviceSynchronize()
			\State cudaEventRecord($start$)
			\State cudaMemPrefetchAsync($ptr$, $bytes$, cudaCpuDeviceId)
			\State cudaEventRecord($stop$)
			\State cudaEventSynchronize($stop$)
			\State $millis \gets$ cudaEventElapsedTime($start$, $stop$)
			\State state.SetIterationTime($\frac{millis}{1000}$)
		\EndFor
		\EndFunction			
	\end{algorithmic}
\end{algorithm}


Listing~\ref{lst:cpu-write} shows a simple function to write \texttt{sizeof(data\_type)} bytes to every \texttt{stride} byte in a \texttt{count}-byte region starting at \texttt{ptr}.
When \texttt{stride} is the page size, each page is written only once, doing the minimal amount of work to force a page migration.

\begin{lstlisting}[language=c++, caption=\texttt{cpu\_write} function., label=lst:cpu-write]
static void 
cpu_write(char *ptr, const size_t count, const size_t stride) {
  for (size_t i = 0; i < count; i += stride) {
    benchmark::DoNotOptimize(ptr[i] = 0);
  }
}
\end{lstlisting}

Listing~\ref{lst:gpu-write} shows CUDA kernel to write \texttt{sizeof(data\_type)} bytes to every \texttt{stride} byte in a \texttt{count}-byte region starting at \texttt{ptr}.
It assigns consecutive warps in the grid to handle consecutive writes, with a single thread from each warp doing a write.
If there are not sufficient warps in the grid to cover all writes, the grid loops over the required writes.
Since warps execute in lockstep, this ensures the broadest simultaneous demands on the unified memory system without redundant work within a warp.

\begin{lstlisting}[language=c++, caption=\texttt{gpu\_write} function., label=lst:gpu-write]
    template <typename data_type>
    __global__ void gpu_write(data_type *ptr,
                              const size_t count,
                              const size_t stride)
    {
    
      size_t gx = 
        blockIdx.x * blockDim.x + threadIdx.x;
      size_t lx = gx & 31;
      size_t wx = gx / 32;
      size_t numWarps = 
        (gridDim.x * blockDim.x + 32 - 1) / 32;
      size_t numStrides = count / stride;
      size_t numData = count / sizeof(data_type);
      size_t dataPerStride = 
        stride / sizeof(data_type);
    
      if (0 == lx)
      {
        for (; wx < numStrides; wx += numWarps)
        {
          const size_t id = wx * dataPerStride;
          if (id < numData)
          {
            ptr[id] = 0;
          }
        }
      }
    }
\end{lstlisting}

%
%
%
\section{Coherence vs Prefetch Bandwidth}
\label{sec:um-coherence-prefetch}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/s822lc_prefetch_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-s822lc-cpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/s822lc_coherence_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-s822lc-cpu-gpu}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/ac922_prefetch_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-ac922-cpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/ac922_coherence_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-ac922-cpu-gpu}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_prefetch_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-dgx-cpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_coherence_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-dgx-cpu-gpu}
	\end{subfigure}
	\caption[CPU/GPU Coherence and Prefetch Bandwidth]{
		Measured CPU-GPU coherence and prefetch bandwidth vs. transfer size  for S822LC, AC922, and DGX-1.
		Local and remote transfers in the CPU-to-GPU and GPU-to-CPU direction are shown.
	}
	\label{fig:um-cpu-gpu}
\end{figure}

Figure~\ref{fig:um-cpu-gpu} compares CPU/GPU prefetch and coherence bandwidth on S822LC, AC922, and DGX-1.
Prefetch provides substantially higher bandwidth than coherence demands, especially for large transfers.
This is likely because the DMA associated with a prefetch is a simpler and higher-performance operation than the on-demand migration of pages.
Prefetch is still lower performance than CPU-to-GPU transfers from pinned memory.
Prefetch must still obey consistency and coherency requirements of the unified memory system, which is a cost not present in explicit data transfer.

On the IBM systems, prefetch bandwidth between local devices is higher than between remote devices (Figures~\ref{fig:um-prefetch-s822lc-cpu-gpu} and \ref{fig:um-prefetch-ac922-cpu-gpu}).
The hardware/software overhead of the unified memory prefetch is low enough to exercise a majority of the availably underlying hardware links, so the more limited performance of the X bus in the remote transfers is likely the cause.
The situation is reversed on DGX-1 (Figure~\ref{fig:um-prefetch-dgx-cpu-gpu}), where GPU to CPU transfers manage to match the performance of pinned explicit transfers, and CPU to GPU transfers do not.
Overall, the prefetch bandwidth is closely correlated with the underlying hardware link performance, with AC922 providing much more bandwidth than the other two systems.

All three systems share behavior for coherence bandwidth (Figures~\ref{fig:um-coherence-s822lc-cpu-gpu}, \ref{fig:um-coherence-ac922-cpu-gpu}, and \ref{fig:um-coherence-dgx-cpu-gpu}).
In these measurements, CPU to GPU performance exceeds GPU to CPU performance due to only using a single CPU thread to generate coherence requests.
On S822LC and AC922, there is a peak in coherence bandwidth at intermediate transfer sizes.
On DGX-1, coherence requests actually provide higher bandwidth at small transfer sizes.
This may be due to reduced overhead for small number of coherence requests compare to setting up an bulk prefetch.
Investigating the details of unified memory performance for different thread counts is under consideration as future work.

\subsection{Device Affinity and Coherence Bandwidth}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/s822lc_prefetch_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-s822lc-gpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/s822lc_coherence_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-s822lc-gpu-gpu}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/ac922_prefetch_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-ac922-gpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/ac922_coherence_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-ac922-gpu-gpu}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_prefetch_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-dgx-gpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_coherence_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-dgx-gpu-gpu}
	\end{subfigure}
	\caption[GPU/GPU Coherence and Prefetch Bandwidth]{
		Measured GPU/GPU coherence and prefetch bandwidth vs. transfer size for S822LC, AC922, and DGX-1.
		Local and remote transfers in both directions for each pair of GPUs are shown.
		For S822LC, anisotropy on GPU-GPU transfers is also shown.
		Similar anisotropy was not observed on AC922 or DGX-1.
	}
	\label{fig:um-gpu-gpu}
\end{figure}

Observed coherence transfer bandwidth is correlated with device affinity; Table~\ref{tab:um-coherence-affinity} summarizes the observed effects.
The effect for CPU-to-GPU transfers is small but measurable on all three systems, as shown in Figures \ref{fig:um-coherence-s822lc-cpu-gpu},~\ref{fig:um-coherence-ac922-cpu-gpu},~and~\ref{fig:um-coherence-dgx-cpu-gpu}.
There is also a small, measurable effect for GPU to CPU transfers, though using a single CPU thread may be obfuscating a larger difference.
This small effect is probably due to overhead of ensuring coherence, so reduced link bandwidth in remote transfers is not a highly influential effect.

Figure~\ref{fig:um-gpu-gpu} compares GPU/GPU prefetch and coherence bandwidth on S822LC, AC922, and DGX-1.
For GPU-GPU transfers, the effect of device affinity on coherence bandwidth is much stronger.
On S822LC, local transfers achieve around $30\%$ higher bandwidth.
The local bandwidth is nearly $100\%$ higher on DGX, and also on AC922 for intermediate transfer sizes.

\begin{table}[ht]
	\centering
	\caption[Device Affinity and Coherence Bandwidth]{
		Observed cases of device affinity affecting coherence bandwidth.
	}
	\label{tab:um-coherence-affinity}
	\begin{tabular}{cccc}
		\hline
		\textbf{Transfer Kind}    & \textbf{S822LC}                                         & \textbf{AC922}                                         & \textbf{DGX-1}                                      \\ \hline 
		CPU $\rightarrow$     GPU & small (Fig.~\ref{fig:um-coherence-s822lc-cpu-gpu})      & $\times$   (Fig.~\ref{fig:um-coherence-ac922-cpu-gpu}) & small (Fig.~\ref{fig:um-coherence-dgx-cpu-gpu}) \\ \hline
		CPU $\leftarrow$      GPU & \checkmark (Fig.~\ref{fig:um-coherence-s822lc-cpu-gpu}) & small (Fig.~\ref{fig:um-coherence-ac922-cpu-gpu})      & small (Fig.~\ref{fig:um-coherence-dgx-cpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU & \checkmark (Fig.~\ref{fig:um-coherence-s822lc-gpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-ac922-gpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-dgx-gpu-gpu}) \\ \hline
	\end{tabular}
\end{table}


\subsection{Device Affinity and on Prefetch Bandwidth}

Device affinity can affect the observed prefetch bandwidth.
Table~\ref{tab:um-prefetch-affinity} shows some cases where affinity affects prefetch transfer bandwidth.
Figures \ref{fig:um-prefetch-s822lc-cpu-gpu}~and~\ref{fig:um-prefetch-ac922-cpu-gpu} show that CPU/GPU prefetch bandwidth is strongly correlated with device affinity on S822LC and AC922.
The overhead of prefetch transfers is lower than coherence transfers, and the availability of bandwidth on the underlying links has a large impact.
On DGX-1 (Figure~\ref{fig:um-prefetch-dgx-cpu-gpu}), bandwidth is not at all correlated with device affinity, in fact, for GPU-to-CPU transfers, remote bandwidth is higher than local bandwidth.
The hardware bandwidth on DGX-1 is much lower, and other implementation details control the performance.

Figures \ref{fig:um-prefetch-s822lc-gpu-gpu}, \ref{fig:um-prefetch-ac922-gpu-gpu}, and \ref{fig:um-prefetch-dgx-gpu-gpu} show that like coherence bandwidth GPU-GPU affinity is strongly correlated with prefetch bandwidth.
On all systems, local GPUs can prefetch data much faster than remote GPUs.
On S822LC, local GPUs enjoy $130\%$ of the transfer bandwidth of their remote companions.
On DGX-1, it is $170\%$, and on AC922, that number balloons to $230\%$.
Generally, local GPU-GPU transfers are able to saturate around $90$\% of the theoretical underlying link bandwidth, just like pinned transfers.

\begin{table}[ht]
	\centering
	\caption[Device Affinity and prefetch Bandwidth]{
		Observed cases of device affinity affecting prefetch bandwidth.
	}
	\label{tab:um-prefetch-affinity}
	\begin{tabular}{cccc}
		\hline
		\textbf{Transfer Kind}    & \textbf{S822LC}                                        & \textbf{AC922}                                        & \textbf{DGX-1}                                      \\ \hline 
		CPU $\rightarrow$     GPU & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-cpu-gpu}) & $\times$   (Fig.~\ref{fig:um-prefetch-dgx-cpu-gpu}) \\ \hline
		CPU $\leftarrow$      GPU & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-cpu-gpu}) & $\times$   (Fig.~\ref{fig:um-prefetch-dgx-cpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-gpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-gpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-dgx-gpu-gpu}) \\ \hline
	\end{tabular}
\end{table}

\subsection{Observed Anisotropy in Coherence Bandwidth}

Table~\ref{tab:um-coherence-anisotropy} describes instances of observed anisotropy in coherence bandwidth.
All CPU/GPU coherence transfers show anisotropy due to the single CPU thread vs multiple GPU threads making accesses.
On all systems, GPU-to-CPU transfers can be around twice the performance for small transfers, but for larger sizes the bandwidth saturates at the rate a single CPU thread can generate requests.
On S822LC, Figure~\ref{fig:um-coherence-dgx-gpu-gpu} there is ansiotropy present in remote GPU-to-GPU transfers.
Similar GPU-GPU bandwidth anisotropy was not observed in any other cases.

\begin{table}[ht]
	\centering
	\caption[Anisotropy in Coherence Bandwidth]{
		Cases where anisotropy is observed in coherence bandwidth.
	}
	\label{tab:um-coherence-anisotropy}
	\begin{tabular}{cccc}
		\hline
		\textbf{Transfer Kind}             & \textbf{S822LC}                                         & \textbf{AC922}                                         & \textbf{DGX-1}                                      \\ \hline 
		CPU $\leftrightarrow$ GPU (local)  & \checkmark (Fig.~\ref{fig:um-coherence-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-ac922-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-dgx-cpu-gpu}) \\ \hline
		CPU $\leftrightarrow$ GPU (remote) & \checkmark (Fig.~\ref{fig:um-coherence-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-ac922-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-dgx-cpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU (local)  & $\times$   (Fig.~\ref{fig:um-coherence-s822lc-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-coherence-ac922-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-coherence-dgx-gpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU (remote) & \checkmark (Fig.~\ref{fig:um-coherence-s822lc-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-coherence-ac922-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-coherence-dgx-gpu-gpu}) \\ \hline
	\end{tabular}
\end{table}

\subsection{Observed Anisotropy in Prefetch Bandwidth}

Table~\ref{tab:um-prefetch-anisotropy} describes instances of observed anisotropy in prefetch bandwidth.

Figures~\ref{fig:um-prefetch-s822lc-cpu-gpu} shows limited anisotropy on local CPU/GPU transfers on S822LC, though there is substantial anisotropy for remote CPU/GPU transfers.
For S822LC remote transfers, as well as on AC922 and DGX-1, there is significant CPU/GPU coherence transfer anisotropy.
On DGX-1, GPU-to-CPU transfers are always faster.
On AC922 and S822LC, GPU-to-CPU transfers are faster for local transfers and CPU-to-GPU transfers are faster for remote devices.

\begin{table}[ht]
	\centering
	\caption[Anisotropy in Prefetch Bandwidth]{
		Cases where anisotropy is observed in prefetch bandwidth.
	}
	\label{tab:um-prefetch-anisotropy}
	\begin{tabular}{cccc}
		\hline
		\textbf{Transfer Kind}             & \textbf{S822LC}                                        & \textbf{AC922}                                        & \textbf{DGX-1}                                      \\ \hline 
		CPU $\leftrightarrow$ GPU (local)  & $\times$   (Fig.~\ref{fig:um-prefetch-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-dgx-cpu-gpu}) \\ \hline
		CPU $\leftrightarrow$ GPU (remote) & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-dgx-cpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU (local)  & $\times$   (Fig.~\ref{fig:um-prefetch-s822lc-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-prefetch-ac922-gpu-gpu}) & $\times$ (Fig.~\ref{fig:um-prefetch-dgx-gpu-gpu})   \\ \hline
		GPU $\leftrightarrow$ GPU (remote) & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-prefetch-ac922-gpu-gpu}) & $\times$ (Fig.~\ref{fig:um-prefetch-dgx-gpu-gpu})   \\ \hline
	\end{tabular}
\end{table}

%
%
%
\section{Page Fault Latency}
\label{sec:um-page-fault}

Unified memory page fault latency is estimated by constructing a linked list in managed memory and traversing it.
Algorithm~\ref{alg:um-latency} summarizes the measurement routine.
The stride between linked list elements is a large number, to avoid prefetching effects on page faults.
The managed memory allocation is prefetched to the source, and a single-threaded traversal function (shown in Listings \ref{lst:gpu-traversal} and \ref{lst:cpu-traversal}) is executed on the destination.
Each access to the list incurs a page fault.
The incremental change in function execution time as the number of strides increases is therefore an approximate measure of the page fault latency.


\begin{lstlisting}[language=c++, caption=GPU Linked List Traversal Kernel for Algorithm~\ref{alg:um-latency}, label=lst:gpu-traversal]
__global__ void gpu_traverse(size_t *ptr, const size_t steps)
{
  size_t next = 0;
  for (int i = 0; i < steps; ++i)
  {
    next = ptr[next];
  }
  ptr[next] = 1;
}
\end{lstlisting}

\begin{lstlisting}[language=c++, caption=CPU Linked List Traversal Function for Algorithm~\ref{alg:um-latency}, label=lst:cpu-traversal]
void cpu_traverse(size_t *ptr, const size_t steps)
{
  size_t next = 0;
  for (size_t i = 0; i < steps; ++i)
  {
    next = ptr[next];
  }
  ptr[next] = 1;
}
\end{lstlisting}

\begin{algorithm}
	\caption{Page Fault Latency}
	\label{alg:um-latency}
	\begin{algorithmic}[1]
		\Statex
		\Function{latency}{$dst$, $src$, $ptr$, $count$, $stride$}
				
        \If{$src$ is CPU}
            \State \texttt{bind\_cpu($src$)}
        \EndIf
        \If{$dst$ is CPU}
            \State \texttt{bind\_cpu($dst$)}
        \EndIf

        \State $blockDim \gets [1,1,1]$ 
        \State $gridDim \gets [1,1,1]$
        \State $stride \gets PAGE\_SIZE \times 2$
        \State $count \gets sizeof(size\_t) \times (steps + 1) \times stride$

        \State $ptr \gets \texttt{cudaMallocManaged(count))}$

        \For{ $i$ in $steps$}
            \State ptr[$i$] $\gets$ $(i+1)\times stride$
        \EndFor
        \State \texttt{cudaDeviceSynchronize()}

        \State $elapsed \gets \infty$
        \For{ $i$ in $numIters$}
            \State $\texttt{cudaMemPrefetchAsync(ptr, count, src))}$
            \State $\texttt{cudaDeviceSynchronize()}$

            \State $start \gets \texttt{wall\_time()}$

            \If{$dst$ is GPU}
                \State \texttt{gpu\_traverse<<<1,1>>>($ptr$, $steps$)}
            \Else
                \State \texttt{cpu\_traverse($ptr$, $steps$)}
            \EndIf

            \State $end \gets \texttt{wall\_time()}$
        \EndFor

		\EndFunction
				
	\end{algorithmic}
\end{algorithm}

Table~\ref{tab:page-fault-latency} summarizes the estimated page fault latencies.
Figure~\ref{fig:coherence-page-fault-latency} shows the raw traversal times.
There is no substantial difference in page fault latencies for different CPUs, so values for transfers to CPU0 are shown.

All three systems follow the same behavior, with GPU/GPU page fault latencies being higher than CPU/GPU page fault latencies.
The bottom section of Table~\ref{tab:page-fault-latency} shows that the cost of moving the page is a small portion of the observed transfer time.
These calculated values do not include link latencies, and represent a lower bound.
On S822LC and AC922, the CPU/GPU page fault latency is nearly identical in both directions.


\begin{table}[ht]
	\centering
	\caption[Page Fault Latencies]{
        Measured page-fault latencies on S822LC, AC922, and DGX-1.
        Above the double-line are empirically-measured values.
        Below the double-line are computed values, for the system page size and system configuration.
        The value is computed by taking the link bandwidth and dividing it by the page size.
        e.g., NVLink for S822LC refers to two-lane NVLink 1.0.
    }
	\label{tab:page-fault-latency}
	\begin{tabular}{cccc}
        \hline
        \textbf{Page Fault}                  & \multicolumn{3}{c|}{\textbf{Latency ($\mu$s)}}    \\ \hline
		\textbf{Type}                        & \textbf{S822LC} & \textbf{AC922} & \textbf{DGX-1} \\ \hline
		CPU  $\leftarrow$  GPU               & 13.7            & 26.9           & 26.6           \\ \hline
		CPU  $\rightarrow$ GPU               & 16.3            & 23.7           & 32.2           \\ \hline
		GPU0 $\leftrightarrow$ GPU1 (local)  & 27.6            & 39.1           & 37.1           \\ \hline
        GPU0 $\leftrightarrow$ GPU2 (remote) & 28.3            & 39.0           & 50.3           \\ \hline
        \hline
        One Page, PCIe 3.0 x16               & N/A             & N/A            & 0.25           \\ \hline
        One Page, NVLink                     & 1.6             & 0.9            & 0.4            \\ \hline
	\end{tabular}
\end{table}


\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.31\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/m2_coherence_latency.pdf}
		\caption{}
		\label{fig:s822lc-page-fault}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.31\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/hal_coherence_latency.pdf}
		\caption{}
		\label{fig:ac922-page-fault}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.31\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_coherence_latency.pdf}
		\caption{}
		\label{fig:dgx-page-fault}
	\end{subfigure}
	\caption[Page Fault Latencies for S822LC, AC922, and DGX-1]{
        Linked-list traversal time vs number of strides for S822LC, AC922, and DGX-1.
        For each system, CPU-to-GPU, GPU-to-CPU, and remote/local GPU-to-GPU times are shown.
        Each stride incurs a page fault, so the slope of these lines estimate the page fault cost.
    }
	\label{fig:coherence-page-fault-latency}
\end{figure}

\section{Summary}

The unified memory system comes at a significant performance penalty compared to explicit memory management, and suffers from similar topological performance effects.
Unsurprisingly, performance is strongly correlated with device affinity, particularly for prefetch bandwidth.
Performance anisotropy is observed in nearly all prefetch benchmarks and many coherence benchmarks.
Achievable coherence performance ranges from around $30\%$-$90\%$ of the best possible explicit performance, with more degredation on higher-performance links.
With the additional programmer effort of including prefetching hints, performance nearly equal to the explicit data transfer can be achieved.
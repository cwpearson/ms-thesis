\chapter{Unified Memory Performance}
\label{ch:unified}

The unified memory system (Sections~\ref{sec:unified-cc3} and \ref{sec:unified-cc6}) greatly simplifies the programmer interaction with CUDA memories and data transfer.
Data tranfers in the unified memory system are created in two ways:
\begin{itemize}
	\item \textit{coherence} (or \textit{demand}) transfers, where data is migrated to ensure that the CPU and GPU have a consistent view of memory.
	\item \textit{prefetch} transfers, where data is moved ahead of time, with the purpose of reducing future access times. 
\end{itemize}
This chapter comprises two sections, detailing performance of prefetch and coherence unified memory bandwidth (Section~\ref{sec:um-coherence-prefetch}), and page fault latency (Section~\ref{sec:um-page-fault}).
In each section, transfer bandwidth for coherence and prefetch transfers is examined, as well as page-fault latency for demand transfers, where applicable.

Algorithm~\ref{alg:um-bw-gpu-gpu} describes the approach to measure coherence or prefetch bandwidth between two GPUs in the unified memory system.
First, a $bytes$-size unified memory allocation at $ptr$ is associated with the destination device.
As of the time of this writing, this choice of association should not affect the benchmark, but is enforced for consistency.
Then, \texttt{memset} is used to force pages backing the allocation to be produced.
A $start$ and $stop$ event is created on the destination device, where the kernel will be executed for coherence bandwidth measurements.
During the benchmark loop, $ptr$ is prefetch to the source device.
Then, for coherence bandwidth, \texttt{gpu\_write} is executed on the destination device, or for prefetch bandwidth, \texttt{cudaMemPrefetchAsync} is used to prefetch $ptr$ to the destination device.
\texttt{cudaEventSyncrhonize} is used to ensure the coherence or prefetch workload is complete.
The time for the CPU workload or GPU workload and synchronization is recorded as the iteration time.
The benchmark is repeated five times to discover outliers and establish a standard deviation of measurement.

\begin{algorithm}[H]
	\caption[Measuring GPU-GPU Unified Memory Coherence or Prefetch Bandwidth.]{
		Measuring GPU-GPU unified memory coherence or prefetch bandwidth during a $bytes$-sized transfer between $src$ and $dst$.
		\texttt{gpu\_write} is defined in Listing~\ref{lst:gpu-write}.
	}
	\label{alg:um-bw-gpu-gpu}
	\begin{algorithmic}[1]
		\Statex
		\Function{Bandwidth}{$dst$, $src$, $bytes$}
		
		\State $pageSize \gets$ sysconf(\_SC\_PAGESIZE)
		\State cudaSetDevice($dst$)
		\State $ptr \gets$ \texttt{cudaMallocManaged($bytes$)}
		\State \texttt{memset($ptr$, 0, $bytes$)} \Comment force pages to be allocated

		\State cudaEventCreate($start$)
		\State cudaEventCreate($stop$)		        
				
		\For{$state$}
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$) \Comment move pages to $src$
			\State cudaSetDevice($src$)
			\State cudaDeviceSynchronize()
			\State cudaSetDevice($dst$)
			\State cudaDeviceSynchronize()
			\State cudaEventRecord($start$)
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$) \Comment if prefetch, or...
			\State \texttt{gpu\_write<<<$256$,$256$>>>($ptr$, $bytes$, $pageSize$)} \Comment if coherence
			\State cudaEeventRecord($stop$)
			\State cudaEventSynchronize($stop$)
			\State $millis \gets$ cudaEventElapsedTime($start$, $stop$)
			\State state.SetIterationTime($\frac{millis}{1000}$)
		\EndFor
		\EndFunction			
	\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:um-bw-cpu-gpu} describes the approach to measure coherence or prefetch bandwidth from a CPU to a GPU in the unified memory system.
First, execution is bound to the source NUMA node.
Then, the destination CUDA device is set to be active, a $bytes$-sized unified memory allocation is created, and \texttt{cudaMemset} is used to ensure that pages for the allocation are created.
During the event loop, \texttt{cudaMemPrefetchAsync} followed by \texttt{cudaDeviceSynchronize} ensure that unified memory pages are on the source CPU.
Then, the \texttt{gpu\_write} (Listing~\ref{lst:gpu-write}) is used to generate coherence requests to move pages to the destination GPU, or \texttt{cudaMemPrefetchAsync} is used to prefetch pages to the destination GPU.
CUDA events are used to record the elapsed time, and that is used as the benchmark iteration time.
The benchmark is repeated five times to discover outliers and establish a standard deviation of measurement.

\begin{algorithm}[H]
	\caption[Measuring CPU-GPU Unified Memory Coherence or Prefetch Bandwidth.]{
		Measuring CPU-GPU unified memory coherence or prefetch bandwidth during a $bytes$-sized transfer between $src$ and $dst$.
		\texttt{gpu\_write} is defined in Listing~\ref{lst:gpu-write}.
	}
	\label{alg:um-bw-cpu-gpu}
	\begin{algorithmic}[1]
		\Statex
		\Function{Bandwidth}{$dst$, $src$, $bytes$}
		
		\State numa\_bind\_node($src$)
		\State cudaSetDevice($dst$)

		\State $ptr \gets$ \texttt{cudaMallocManaged($bytes$)}
		\State \texttt{cudaMemset($ptr$, 0, $bytes$)} \Comment force pages to be allocated

		\State $pageSize \gets$ sysconf(\_SC\_PAGESIZE)
		\State cudaSetDevice($dst$)

		\State cudaEventCreate($start$)
		\State cudaEventCreate($stop$)		        
				
		\For{$state$}
			\State cudaMemPrefetchAsync($ptr$, $bytes$, cudaCpuDeviceId) \Comment move pages to CPU
			\State cudaDeviceSynchronize()
			\State cudaEventRecord($start$)
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$) \Comment if prefetch, or...
			\State \texttt{gpu\_write<<<$256$,$256$>>>($ptr$, $bytes$, $pageSize$)} \Comment if coherence
			\State cudaEventRecord($stop$)
			\State cudaEventSynchronize($stop$)
			\State $millis \gets$ cudaEventElapsedTime($start$, $stop$)
			\State state.SetIterationTime($\frac{millis}{1000}$)
		\EndFor
		\EndFunction			
	\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:um-coherence-bw-gpu-cpu} describes the approach to measure coherence bandwidth from a GPU to a CPU in the unified memory system.
First, execution is bound to the destination NUMA node.
Then, the source CUDA device is set to be active, a $bytes$-sized unified memory allocation is created, and \texttt{cudaMemset} is used to ensure that pages for the allocation are created.
During the event loop, \texttt{cudaMemPrefetchAsync} followed by \texttt{cudaDeviceSynchronize} ensure that unified memory pages are on the source GPU.
Then, the \texttt{cpu\_write} (Listing~\ref{lst:gpu-write}) is used to generate coherence requests to move pages to the destination CPU.
The automatic benchmark timing may be used instead of CUDA events, as the CPU accesses are guaranteed to complete from the perspective of the CPU just like normal memory accesses.
The benchmark is repeated five times to discover outliers and establish a standard deviation of measurement.

\begin{algorithm}[H]
	\caption[Measuring GPU-to-CPU Unified Memory Coherence Bandwidth.]{
		Measuring GPU-to-CPU unified memory coherence bandwidth during a $bytes$-sized transfer between $src$ and $dst$.
		\texttt{cpu\_write} is defined in Listing~\ref{lst:cpu-write}.
	}
	\label{alg:um-coherence-bw-gpu-cpu}
	\begin{algorithmic}[1]
		\Statex
		\Function{Bandwidth}{$dst$, $src$, $bytes$}
		
		\State numa\_bind\_node($dst$)
		\State cudaSetDevice($src$)

		\State $ptr \gets$ \texttt{cudaMallocManaged($bytes$)}
		\State \texttt{cudaMemset($ptr$, 0, $bytes$)} \Comment force pages to be allocated

		\State $pageSize \gets$ sysconf(\_SC\_PAGESIZE)
		\State cudaSetDevice($dst$)        
				
		\For{$state$}
			\State state.PauseTiming()
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$)
			\State cudaDeviceSynchronize()
			\State state.ResumeTiming()
			\State cpu\_write($ptr$, $bytes$, $pageSize$)
		\EndFor
		\EndFunction			
	\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:um-prefetch-bw-gpu-cpu} describes the approach to measure coherence bandwidth from a GPU to a CPU in the unified memory system.
It is the same as Algorithm~\ref{alg:um-coherence-bw-gpu-cpu}, except CUDA events are used to time the asynchronous \texttt{cudaMemPrefetchAsync} workload.
The benchmark is repeated five times to discover outliers and establish a standard deviation of measurement.

\begin{algorithm}[H]
	\caption[Measuring GPU-to-CPU Unified Memory Prefetch Bandwidth.]{
		Measuring GPU-to-CPU unified memory prefetch bandwidth during a $bytes$-sized transfer between $src$ and $dst$.
		\texttt{cpu\_write} is defined in Listing~\ref{lst:cpu-write}.
	}
	\label{alg:um-prefetch-bw-gpu-cpu}
	\begin{algorithmic}[1]
		\Statex
		\Function{Bandwidth}{$dst$, $src$, $bytes$}
		
		\State numa\_bind\_node($dst$)
		\State cudaSetDevice($src$)

		\State $ptr \gets$ \texttt{cudaMallocManaged($bytes$)}
		\State \texttt{cudaMemset($ptr$, 0, $bytes$)} \Comment force pages to be allocated

		\State $pageSize \gets$ sysconf(\_SC\_PAGESIZE)
		\State cudaSetDevice($dst$)

		\State cudaEventCreate($start$)
		\State cudaEventCreate($stop$)		        
				
		\For{$state$}
			\State cudaMemPrefetchAsync($ptr$, $bytes$, $src$)
			\State cudaDeviceSynchronize()
			\State cudaEventRecord($start$)
			\State cudaMemPrefetchAsync($ptr$, $bytes$, cudaCpuDeviceId)
			\State cudaEventRecord($stop$)
			\State cudaEventSynchronize($stop$)
			\State $millis \gets$ cudaEventElapsedTime($start$, $stop$)
			\State state.SetIterationTime($\frac{millis}{1000}$)
		\EndFor
		\EndFunction			
	\end{algorithmic}
\end{algorithm}


Listing~\ref{lst:cpu-write} shows a simple function to write \texttt{sizeof(data\_type)} bytes to every \texttt{stride} byte in a \texttt{count}-byte region starting at \texttt{ptr}.
When \texttt{stride} is the page size, each page is written only once, doing the minimal amount of work to force a page migration.

\begin{lstlisting}[language=c++, caption=\texttt{cpu\_write} function., label=lst:cpu-write]
static void 
cpu_write(char *ptr, const size_t count, const size_t stride) {
  for (size_t i = 0; i < count; i += stride) {
    benchmark::DoNotOptimize(ptr[i] = 0);
  }
}
\end{lstlisting}

Listing~\ref{lst:gpu-write} shows CUDA kernel to write \texttt{sizeof(data\_type)} bytes to every \texttt{stride} byte in a \texttt{count}-byte region starting at \texttt{ptr}.
It assigns consecutive warps in the grid to handle consecutive writes, with a single thread from each warp doing a write.
If there are not sufficient warps in the grid to cover all writes, the grid loops over the required writes.
Since warps execute in lockstep, this ensures the broadest simultaneous demands on the unified memory system without redundant work within a warp.

\begin{lstlisting}[language=c++, caption=\texttt{gpu\_write} function., label=lst:gpu-write]
    template <typename data_type>
    __global__ void gpu_write(data_type *ptr,
                              const size_t count,
                              const size_t stride)
    {
    
      size_t gx = 
        blockIdx.x * blockDim.x + threadIdx.x;
      size_t lx = gx & 31;
      size_t wx = gx / 32;
      size_t numWarps = 
        (gridDim.x * blockDim.x + 32 - 1) / 32;
      size_t numStrides = count / stride;
      size_t numData = count / sizeof(data_type);
      size_t dataPerStride = 
        stride / sizeof(data_type);
    
      if (0 == lx)
      {
        for (; wx < numStrides; wx += numWarps)
        {
          const size_t id = wx * dataPerStride;
          if (id < numData)
          {
            ptr[id] = 0;
          }
        }
      }
    }
\end{lstlisting}

%
%
%
\section{Coherence vs Prefetch Bandwidth}
\label{sec:um-coherence-prefetch}

Figure~\ref{fig:um-cpu-gpu} compares CPU/GPU prefetch and coherence bandwidth on S822LC, AC922, and DGX-1.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/s822lc_prefetch_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-s822lc-cpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/s822lc_coherence_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-s822lc-cpu-gpu}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/ac922_prefetch_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-ac922-cpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/ac922_coherence_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-ac922-cpu-gpu}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_prefetch_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-dgx-cpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_coherence_cpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-dgx-cpu-gpu}
	\end{subfigure}
	\caption[CPU/GPU Coherence and Prefetch Bandwidth]{
		Measured CPU-GPU coherence and prefetch bandwidth vs. transfer size  for S822LC, AC922, and DGX-1.
		Local and remote transfers in the CPU-to-GPU and GPU-to-CPU direction are shown.
	}
	\label{fig:um-cpu-gpu}
\end{figure}


In general, the CPU/GPU prefetch bandwidth saturates at a higher fraction of the theoretical underlying link bandwidth than the coherence bandwidth.
This is likely because the DMA associated with a prefetch is a simpler and higher-performance operation than the on-demand migration of pages.
Coherence migrations can provide higher transfer bandwidth at small and intermediate transfer sizes.
This suggests that the overhead of the prefetch transfer is higher than the coherence transfer.
Notably, CPU-GPU transfers on AC922 show some unique performance degradation as transfer sizes get larger.
Due to the construction of the benchmark, the number of GPU threads participating in the transfer grows linearly with the transfer size.
Performance of the unified memory system on S822LC and AC922 may degrade with too many simultaneous pending transfers.

Figure~\ref{fig:um-gpu-gpu} compares GPU/GPU prefetch and coherence bandwidth on S822LC, AC922, and DGX-1.
The GPU/GPU prefetch bandwidth also saturates at a higher bandwidth than the coherence transfers, and like the CPU/GPU transfers, the coherence bandwidth is higher for small and intermediate transfers.
On S822LC and AC922, the achieved bandwidth drop as the transfer size gets larger (except for the S822LC remote case).
This would be consistent with many parallel GPU threads generating too many concurrent page transfer demands.


\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/s822lc_prefetch_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-s822lc-gpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/s822lc_coherence_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-s822lc-gpu-gpu}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/ac922_prefetch_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-ac922-gpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/ac922_coherence_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-ac922-gpu-gpu}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_prefetch_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-prefetch-dgx-gpu-gpu}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_coherence_gpu-gpu.pdf}
		\caption{}
		\label{fig:um-coherence-dgx-gpu-gpu}
	\end{subfigure}
	\caption[GPU/GPU Coherence and Prefetch Bandwidth]{
		Measured GPU/GPU coherence and prefetch bandwidth vs. transfer size for S822LC, AC922, and DGX-1.
		Local and remote transfers in both directions for each pair of GPUs are shown.
	}
	\label{fig:um-gpu-gpu}
\end{figure}



\subsection{Device Affinity and Coherence Bandwidth}

Device affinity affects the observed coherence transfer bandwidth.
Table~\ref{tab:um-coherence-affinity} shows some cases where affinity affects transfer bandwidth.
Figures \ref{fig:um-coherence-s822lc-cpu-gpu} and ~\ref{fig:um-coherence-ac922-cpu-gpu} shows no affinity effect for CPU to GPU coherence traffic.
On AC922, the same is not true for GPU-to-CPU traffic, where local transfers saturate above 40GB/s while remote transfers are limited to around 30 GB/s.
The CPUs on AC922 may be able to generate more coherence requests, or the system may be able to serve them faster, and ultimately the performance is limited by the slower CPU-CPU X bus.

Figures \ref{fig:um-coherence-s822lc-gpu-gpu} and ~\ref{fig:um-coherence-ac922-gpu-gpu} show that affinity influences the performance of GPU-GPU transfers, with local transfers being faster than remote transfers.
The performance difference is much greater for intermediate transfers than large transfers.
\todo{Can we figure out why?}

\begin{table}[ht]
	\centering
	\caption[Device Affinity and Coherence Bandwidth]{
		Observed cases of device affinity affecting coherence bandwidth.
	}
	\label{tab:um-coherence-affinity}
	\begin{tabular}{cccc}
		\hline
		\textbf{Transfer Kind}    & \textbf{S822LC}                                         & \textbf{AC922}                                         & \textbf{DGX-1}                            \\ \hline 
		CPU $\rightarrow$     GPU & $\times$   (Fig.~\ref{fig:um-coherence-s822lc-cpu-gpu}) & $\times$   (Fig.~\ref{fig:um-coherence-ac922-cpu-gpu}) & $\times$ (Fig.~\ref{fig:um-coherence-dgx-cpu-gpu}) \\ \hline
		CPU $\leftarrow$      GPU & $\times$   (Fig.~\ref{fig:um-coherence-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-ac922-cpu-gpu}) & $\times$ (Fig.~\ref{fig:um-coherence-dgx-cpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU & \checkmark (Fig.~\ref{fig:um-coherence-s822lc-gpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-ac922-gpu-gpu}) & $\times$ (Fig.~\ref{fig:um-coherence-dgx-gpu-gpu}) \\ \hline
	\end{tabular}
\end{table}


\subsection{Device Affinity and on Prefetch Bandwidth}

Device affinity can affect the observed prefetch bandwidth.
Table~\ref{tab:um-prefetch-affinity} shows some cases where affinity affects prefetch transfer bandwidth.
Figures \ref{fig:um-prefetch-s822lc-cpu-gpu} and \ref{fig:um-prefetch-ac922-cpu-gpu} show that CPU-GPU prefetch bandwidth is influenced by device affinity.
For S822LC and AC922, the prefetch bandwidth from GPU2 to CPU0 is substantially higher than that of GPU0 to CPU0, even though GPU2 is remote from CPU0 and must traverse more links.
The CPU-to-GPU transfers show more expected behavior, with local transfer bandwidth being higher than remote.
On DGX-1, there is no effect, probably due to the low PCIe bandwidth hiding other factors that might introduce unepxected behavior.

Figures \ref{fig:um-prefetch-s822lc-gpu-gpu}, \ref{fig:um-prefetch-ac922-gpu-gpu}, and \ref{fig:um-prefetch-dgx-gpu-gpu} show that GPU-GPU affinity has a very large effect for prefetch bandwidth.
On all systems, local GPUs can prefetch data much faster than remote GPUs.
On S822LC, local GPUs enjoy $162\%$ of the transfer bandwidth of their remote companions.
On DGX-1, it is $170\%$, and on AC922, that number balloons to $230\%$.
Generally, local GPU-GPU transfers are able to saturate around 75\% of the theoretical underlying link bandwidth.

\begin{table}[ht]
	\centering
	\caption[Device Affinity and prefetch Bandwidth]{
		Observed cases of device affinity affecting prefetch bandwidth.
	}
	\label{tab:um-prefetch-affinity}
	\begin{tabular}{cccc}
		\hline
		\textbf{Transfer Kind}    & \textbf{S822LC}                                        & \textbf{AC922}                                        & \textbf{DGX-1}                                      \\ \hline 
		CPU $\rightarrow$     GPU & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-cpu-gpu}) & $\times$   (Fig.~\ref{fig:um-prefetch-dgx-cpu-gpu}) \\ \hline
		CPU $\leftarrow$      GPU & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-cpu-gpu}) & $\times$   (Fig.~\ref{fig:um-prefetch-dgx-cpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-gpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-gpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-dgx-gpu-gpu}) \\ \hline
	\end{tabular}
\end{table}

\subsection{Observed Anisotropy in Coherence Bandwidth}

Table~\ref{tab:um-coherence-anisotropy} describes instances of observed anisotropy in coherence bandwidth.
Figure~\ref{fig:um-coherence-s822lc-cpu-gpu} shows that CPU-to-GPU coherence transfers are uniformly faster than GPU-to-CPU coherence transfers on S822LC.
On AC922, Figure~\ref{fig:um-coherence-ac922-cpu-gpu} shows that for small transfers, CPU-to-GPU transfers are faster, but the corresponding GPU-to-CPU transfers become larger for large transfers.
The Power9 CPUs may be able to generate more coherence requests once the OpenMP overhead of the benchmark is sufficiently amortized for large transfers.

Figure~\ref{fig:um-coherence-s822lc-gpu-gpu} shows that GPU-GPU S822LC transfers do exhibit anisotropy in large remote coherence transfers, but no other cases.
On AC922, Figure~\ref{fig:um-coherence-ac922-gpu-gpu} shows there is no anisotropic behavior in any GPU-GPU coherence transfers.

\begin{table}[ht]
	\centering
	\caption[Anisotropy in Coherence Bandwidth]{
		Cases where anisotropy is observed in coherence bandwidth.
	}
	\label{tab:um-coherence-anisotropy}
	\begin{tabular}{cccc}
		\hline
		\textbf{Transfer Kind}             & \textbf{S822LC}                                         & \textbf{AC922}                                         & \textbf{DGX-1}                            \\ \hline 
		CPU $\leftrightarrow$ GPU (local)  & \checkmark (Fig.~\ref{fig:um-coherence-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-ac922-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-dgx-cpu-gpu}) \\ \hline
		CPU $\leftrightarrow$ GPU (remote) & \checkmark (Fig.~\ref{fig:um-coherence-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-ac922-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-coherence-dgx-cpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU (local)  & $\times$   (Fig.~\ref{fig:um-coherence-s822lc-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-coherence-ac922-gpu-gpu}) & $\times$ (Fig.~\ref{fig:um-coherence-dgx-gpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU (remote) & \checkmark (Fig.~\ref{fig:um-coherence-s822lc-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-coherence-ac922-gpu-gpu}) & $\times$ (Fig.~\ref{fig:um-coherence-dgx-gpu-gpu}) \\ \hline
	\end{tabular}
\end{table}

\section{Observed Anisotropy in Prefetch Bandwidth}

Table~\ref{tab:um-prefetch-anisotropy} describes instances of observed anisotropy in prefetch bandwidth.

Figure~\ref{fig:um-prefetch-s822lc-cpu-gpu} and \ref{fig:um-prefetch-ac922-cpu-gpu} show CPU-GPU anisotropy on S822LC and AC922.
For local transfers, the CPU-GPU direction is faster.
For remote transfers, the GPU-to-CPU direction is faster.
Figure~\ref{fig:um-prefetch-dgx-cpu-gpu} shows negligable anisotropy on DGX-1, though the GPU-to-CPU direction is always faster.
The relatively low PCIe bandwidth may be hiding other influences.

Fig.~\ref{fig:um-prefetch-s822lc-gpu-gpu} shows anisotropy in remote GPU-GPU prefetch transfers on S822LC.
Neither of the other systems demonstrate any GPU-GPU prefetch anisotropy.

\begin{table}[ht]
	\centering
	\caption[Anisotropy in Prefetch Bandwidth]{
		Cases where anisotropy is observed in prefetch bandwidth.
	}
	\label{tab:um-prefetch-anisotropy}
	\begin{tabular}{cccc}
		\hline
		\textbf{Transfer Kind}             & \textbf{S822LC}                                         & \textbf{AC922}                                         & \textbf{DGX-1}                            \\ \hline 
		CPU $\leftrightarrow$ GPU (local)  & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-cpu-gpu}) & $\times$ (Fig.~\ref{fig:um-prefetch-dgx-cpu-gpu}) \\ \hline
		CPU $\leftrightarrow$ GPU (remote) & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-cpu-gpu}) & \checkmark (Fig.~\ref{fig:um-prefetch-ac922-cpu-gpu}) & $\times$ (Fig.~\ref{fig:um-prefetch-dgx-cpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU (local)  & $\times$   (Fig.~\ref{fig:um-prefetch-s822lc-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-prefetch-ac922-gpu-gpu}) & $\times$ (Fig.~\ref{fig:um-prefetch-dgx-gpu-gpu}) \\ \hline
		GPU $\leftrightarrow$ GPU (remote) & \checkmark (Fig.~\ref{fig:um-prefetch-s822lc-gpu-gpu}) & $\times$   (Fig.~\ref{fig:um-prefetch-ac922-gpu-gpu}) & $\times$ (Fig.~\ref{fig:um-prefetch-dgx-gpu-gpu}) \\ \hline
	\end{tabular}
\end{table}

%
%
%

\section{Page Fault Latency}
\label{sec:um-page-fault}

Unified memory page fault latency is estimated by constructing a linked list in managed memory and traversing it.
Algorithm~\ref{alg:um-latency} summarizes the measurement routine.
The stride between linked list elements is a large number, to avoid prefetching effects on page faults.
The managed memory allocation is prefetched to the source, and a single-threaded traversal function (shown in Listings \ref{lst:gpu-traversal} and \ref{lst:cpu-traversal}) is executed on the destination.
Each access to the list incurs a page fault.
The incremental change in function execution time as the number of strides increases is therefore an approximate measure of the page fault latency.


\begin{lstlisting}[language=c++, caption=GPU Linked List Traversal Kernel for Algorithm~\ref{alg:um-latency}, label=lst:gpu-traversal]
__global__ void gpu_traverse(size_t *ptr, const size_t steps)
{
  size_t next = 0;
  for (int i = 0; i < steps; ++i)
  {
    next = ptr[next];
  }
  ptr[next] = 1;
}
\end{lstlisting}

\begin{lstlisting}[language=c++, caption=CPU Linked List Traversal Function for Algorithm~\ref{alg:um-latency}, label=lst:cpu-traversal]
void cpu_traverse(size_t *ptr, const size_t steps)
{
  size_t next = 0;
  for (size_t i = 0; i < steps; ++i)
  {
    next = ptr[next];
  }
  ptr[next] = 1;
}
\end{lstlisting}

\begin{algorithm}
	\caption{Page Fault Latency}
	\label{alg:um-latency}
	\begin{algorithmic}[1]
		\Statex
		\Function{latency}{$dst$, $src$, $ptr$, $count$, $stride$}
				
        \If{$src$ is CPU}
            \State \texttt{bind\_cpu($src$)}
        \EndIf
        \If{$dst$ is CPU}
            \State \texttt{bind\_cpu($dst$)}
        \EndIf

        \State $blockDim \gets [1,1,1]$ 
        \State $gridDim \gets [1,1,1]$
        \State $stride \gets PAGE\_SIZE \times 2$
        \State $count \gets sizeof(size\_t) \times (steps + 1) \times stride$

        \State $ptr \gets \texttt{cudaMallocManaged(count))}$

        \For{ $i$ in $steps$}
            \State ptr[$i$] $\gets$ $(i+1)\times stride$
        \EndFor
        \State \texttt{cudaDeviceSynchronize()}

        \State $elapsed \gets \infty$
        \For{ $i$ in $numIters$}
            \State $\texttt{cudaMemPrefetchAsync(ptr, count, src))}$
            \State $\texttt{cudaDeviceSynchronize()}$

            \State $start \gets \texttt{wall\_time()}$

            \If{$dst$ is GPU}
                \State \texttt{gpu\_traverse<<<1,1>>>($ptr$, $steps$)}
            \Else
                \State \texttt{cpu\_traverse($ptr$, $steps$)}
            \EndIf

            \State $end \gets \texttt{wall\_time()}$
        \EndFor

		\EndFunction
				
	\end{algorithmic}
\end{algorithm}

Table~\ref{tab:page-fault-latency} summarizes the estimated page fault latencies.
Figure~\ref{fig:coherence-page-fault-latency} shows the raw traversal times.
There is no substantial difference in page fault latencies for different CPUs, so values for transfers to CPU0 are shown.

All three systems follow the same behavior, with GPU/GPU page fault latencies being higher than CPU/GPU page fault latencies.
The bottom section of Table~\ref{tab:page-fault-latency} shows that the cost of moving the page is a small portion of the observed transfer time.
These calculated values do not include link latencies, and represent a lower bound.
On S822LC and AC922, the CPU/GPU page fault latency is nearly identical in both directions.


\begin{table}[ht]
	\centering
	\caption[Page Fault Latencies]{
        Measured page-fault latencies on S822LC, AC922, and DGX-1.
        Above the double-line are empirically-measured values.
        Below the double-line are computed values, for the system page size and system configuration.
        The value is computed by taking the link bandwidth and dividing it by the page size.
        e.g., NVLink for S822LC refers to two-lane NVLink 1.0.
    }
	\label{tab:page-fault-latency}
	\begin{tabular}{cccc}
        \hline
        \textbf{Page Fault}                  & \multicolumn{3}{c|}{\textbf{Latency ($\mu$s)}}    \\ \hline
		\textbf{Type}                        & \textbf{S822LC} & \textbf{AC922} & \textbf{DGX-1} \\ \hline
		CPU  $\leftarrow$  GPU               & 13.7            & 26.9           & 26.6           \\ \hline
		CPU  $\rightarrow$ GPU               & 16.3            & 23.7           & 32.2           \\ \hline
		GPU0 $\leftrightarrow$ GPU1 (local)  & 27.6            & 39.1           & 37.1           \\ \hline
        GPU0 $\leftrightarrow$ GPU2 (remote) & 28.3            & 39.0           & 50.3           \\ \hline
        \hline
        One Page, PCIe 3.0 x16               & N/A             & N/A            & 0.25           \\ \hline
        One Page, NVLink                     & 1.6             & 0.9            & 0.4            \\ \hline
	\end{tabular}
\end{table}


\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.31\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/m2_coherence_latency.pdf}
		\caption{}
		\label{fig:s822lc-page-fault}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.31\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/hal_coherence_latency.pdf}
		\caption{}
		\label{fig:ac922-page-fault}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.31\textwidth}
		\includegraphics[width=\textwidth]{figures/generated/dgx_coherence_latency.pdf}
		\caption{}
		\label{fig:dgx-page-fault}
	\end{subfigure}
	\caption[Page Fault Latencies for S822LC, AC922, and DGX-1]{
        Linked-list traversal time vs number of strides for S822LC, AC922, and DGX-1.
        For each system, CPU-to-GPU, GPU-to-CPU, and remote/local GPU-to-GPU times are shown.
        Each stride incurs a page fault, so the slope of these lines estimate the page fault cost.
    }
	\label{fig:coherence-page-fault-latency}
\end{figure}

\section{Summary}

The performance of the unified memory system deviates from expectations in substantial ways:
\begin{itemize}
\item CPU-to-GPU coherence bandwidth is higher than prefetch bandwidth for small / intermediate transfer sizes.
\item S822LC and AC922 exhibit faster remote GPU-GPU prefetch bandwidth than local GPU-GPU prefetch bandwidth.
\item DGX-1 GPU-CPU prefetch bandwidth is not affected by device affinity.
\item S822LC is alone in exhibiting remote GPU-GPU prefetch anisotropy.
\item Anisotropy is observed in a wide variety of cases
\item AC922 and DGX-1 have better CPU-to-GPU coherence bandwidth for smaller transfers and better GPU-to-CPU coherence bandwidth for large cases, while S822LC always demonstrates better CPU-to-GPU than GPU-to-GPU coherence bandwidth.
\item IBM CPU/GPU prefetch bandwidth is anisotropic and affected by affinity.
\end{itemize}
However, the performance of the unified memory system is no more surprising than that of the explicit transfer system, and with hints from the application developer, can achieve the same effective performance as the explicit system.
In this way, the application developer is able to have the best of both worlds: detailed performance or simpler application development when desired.
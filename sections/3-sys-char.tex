\chapter{System Characterization}
\label{ch:sys-char}

High-performance data movement in heterogeneous systems requires information about the properties of the communication links between system storage and compute components.
Although specifications of system components are often available\todo{cite some examples}, the real-world properties of these links depends on how applications use the links, and whether or not the links are shared between system components.
\todo{For example, Figure~\ref{fig:actual-perf} shows modeled and achieved cuda memcpy bandwidth.}
With full knowledge of link properties it is possible to derive an accurate model of link performance, that approach has two key barriers
\begin{itemize}
    \item Detailed link hardware properties are not available, e.g., when the link provides a competitive advantage for an OEM.
    \item Detailed link software properies are not available, e.g., when the drivers are proprietary.
    \item Even if a link is pysically present on the system, it may not be available to the application {e.g., due to bugs in the system configuration}
\end{itemize}
Instead of deriving a model of link performance from the ``first principles'' of link properties, this work attempts to generate an empirical model of performance of data movement in the system.
Section~\ref{sec:system-model} describes an overview of the system model.
Section~\ref{sec:topology-exploration} describes a method for discovering data sources, sinks, and communication paths in a system.
Section~\ref{sec:link-char} describes the approach to characterize communication links.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth,draft]{../figures/actual-cuda-memcpy.png}
    \caption[\todo{short}]{\todo{long}}
    \label{fig:actual-cuda-memcpy}
\end{figure}

\section{System Model}
\label{sec:system-model}

The harware system is represented by a graph $G_s = \{E,V\}$ where $E$ is a set of edges representing communication links, and $V$ is a set of vertices representing data sources/sinks.
Sections~\ref{sec:system-vertices} and \ref{sec:system-edges} describe the specific system components explored.
Associated with each edge is a performance model function $M: C,U \rightarrow P$ that maps a communication pattern $C$ and a link utilization $U$ to an achievable performance $P$.

The communication pattern $P$ has the following parameters:
\begin{itemize}
    \item The communication API or method used (e.g., \texttt{fread()}, CUDA unified memory page transfer).
    \item The number, size, and priority of pending transfers on the link.
\end{itemize}

The link utilization $U$ a set of extant communication patterns already sharing the link, separate from the communication of interest $C$.



Each vertex in $V$ represents a data source/sink.



%
% SECTION
%
\section{Topology Exploration}
\label{sec:topology-exploration}

The topology exploration is done in several phases:

\begin{minipage}[h]{\textwidth}
\begin{enumerate}
    \item Enumerate and link CPU sockets
    \item Enumerate PCI devices
    \item Update GPUs to NVIDIA GPUs as appropriate
    \item Enumerate Linux block devices
\end{enumerate}
\end{minipage}

First, the Portable Hardware Locality~\cite{broquedis2010hwloc} (hwloc) library is used to enumerate the present CPU sockets.
As the test systems only have two sockets, all discovered sockets are considered to be directly connected by an SMP bus.
Next, hwloc is used to descend through the PCI device tree and connect all PCI devices with PCI links of the appropriate type.
Next, the NVIDIA Management Library~\cite{nvidia2017nvml} (NVML) is used to enumerate all NVIDIA GPUs.
Those GPUs are matched by PCI address with previously-discovered PCI devices and information about those GPUs is added to $G_s$.
NVML is then used to discover whether NVLink is supported on each GPU, and which device the NVLink terminates at.
Finally, linux block devices are enumerated through \todo{more detail} and added to $G_s$.
Where applicable, enough information about the device is stored within the vertex to be able to access the device later.

\subsection{Vertex Types}
\label{sec:system-vertices}

Table~\ref{tab:topology-vertices} summarizes the discoverable types of data sources and sinks investigated by this work.


\begin{table}[]
    \centering
    \caption[Discoverable vertex types]{\todo{long caption}}
    \label{tab:topology-vertices}
    \begin{tabular}{|c|c|}
    \hline
    \textbf{Vertex Type}    & \textbf{Description} \\ \hline
    CPU Socket              &                      \\ \hline
    PCI Device              &                      \\ \hline
    PCIe Hostbridge         &                      \\ \hline
    PCIe Bridge             &                      \\ \hline
    CUDA GPU                &                      \\ \hline
    Linux Block Device      &                      \\ \hline
    Linux Network Interface &                      \\ \hline
    \end{tabular}
\end{table}

\subsection{Edge Types}
\label{sec:system-edges}

In $G_s$, the vertices are connected by the discoverable edge types shown in Table~\ref{tab:topology-edges}.

\begin{table}[]
    \centering
    \caption[Discoverable edge types]{\todo{long caption}}
    \label{tab:topology-edges}
    \begin{tabular}{|c|c|}
    \hline
    \textbf{Edge Type} & \textbf{Description} \\ \hline
    SMP Bus            &                      \\ \hline
    PCIe Bus           &                      \\ \hline
    NVLink             &                      \\ \hline
    SATA Bus           &                      \\ \hline
    \end{tabular}
\end{table}



%
% SECTION
%
\section{Link Characterization}
\label{sec:link-char}

After the system graph $G_s$ has been generated, the next task is to characterize the communication capabilities of the system.
The goal of this characterization is to determine the rate at which data of a particular size can be moved between devices.
Ideally, this characterization would occur on a per-link basis along each available path between two communicating devices.
In practice, the communication between many devices is mediated by APIs exposed by the operating system or vendor library.
These APIs abstract away some complexity from the data movement.

\begin{figure}
    \centering
    \begin{tikzpicture}[
        cpunode/.style={circle, draw=green!60, fill=green!5, very thick, minimum size=7mm},
        gpunode/.style={rectangle, draw=red!60, fill=red!5, very thick, minimum size=5mm},
        blocknode/.style={rectangle, draw=red!60, fill=red!5, very thick, minimum size=5mm},
        ]
        %Nodes
        \node[cpunode]   (s0)                  {Socket0};
        \node[blocknode] (b0)    [below=of s0] {Disk0};
        \node[cpunode]   (s1)    [right=of s0] {Socket1};
        \node[gpunode]   (g0)    [below=of s1] {GPU0};

        %Lines
        \path[-] (s0.east)  edge node [above] {SMP}    (s1.west);
        \path[-] (s0.south) edge node [left]  {PCIe0}  (b0.north);
        \path[-] (s1.south) edge node [right] {PCIe1}  (g0.north);
    \end{tikzpicture}
    \caption[A simple example topology]{\todo{clean this up}\todo{long caption}}
    \label{fig:simple-topology}
\end{figure}

For example, consider the simple example system topology in Figure~\ref{fig:simple-topology}.
If a CPU thread running on CPU1 calls \texttt{fread()} to move a block of data from Disk0 to the memory associated with CPU1, the OS will transparently move that data along the PCIe0 and SMP0 links.
Since this capability is exposed to applications, it is useful to characterize it as well, not just the intermediate PCIe0 and SMP links.

An overview of the characterization algorithm is shown in Algorithm~\ref{alg:link-char}.

\begin{algorithm}[ht]
    \SetAlgoLined
    \KwResult{Characterization of all links between all vertices in $G_s$ }
     Build $G_s$ as described in Section~\ref{sec:topology-exploration}\;
     \For{$v_1$ in $V$}{
         \For{$v_2$ in $V$}{
             \If{$v_1 \ne v_2$}{
                Chars $\gets$ SupportedCharacterizers($v_1$,$v_2$)\;
                \For{c in Chars} {
                    c($v_1$, $v_2$)\;
                }
             }
         }
     }
     \caption{Link characterization.}
     \label{alg:link-char}
\end{algorithm}

For each pair of vertices, \todo{hwcomm} determines whether direct communication between those vertices is supported by the operating system or vendor libraries.
For vertices with a path of more than one link between them (e.g. Disk0 to Socket1 in Figure~\ref{fig:simple-topology}) those individual links will be characterized separately.
For vertices with multiple paths between them, the characterized path will be implicity chosen by the applied characterization method.





Other links, like CPU-GPU PCIe links (e.g., edge ``PCIe'' in Figure~\ref{fig:simple-topology}), are used by invoking a vendor API such as CUDA or OpenCL.

\subsubsection{CUDA \texttt{cudaMemcpy} with Pinned Memory}
\subsubsection{CUDA \texttt{memcpyPeer}}
\subsubsection{CUDA Unified Memory}
\subsubsection{OpenMP Socket to Socket Bandwidth}

The symmetric multi-processing links between CPU sockets are characterized by a synthetic workload generating using OpenMP~\cite{openmp2013}.



%
% SECTION
%
\section{System Characterization Case Studies}

\subsection{IBM S822LC ``Minsky''}
\label{sec:topology-minsky}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth,draft]{../figures/explore-topo-minsky.pdf}
    \caption[\todo{short}]{\todo{long}}
    \label{fig:actual-perf}
\end{figure}

The IMB ``Minsky'' machine consists of two isomorphic sections, connected by an IBM X bus between two 10-core Power8+ CPUs with 8-way simultaneous multithreading (SMT).
Each CPU is connected to 256GB of \todo{DDR4} RAM.
Each CPU is also connected to two NVIDIA Tesla P100 GPUs by two NVLink blocks.
Those P100s within the isomorphic section are also connected to each other by two NVLink blocks.
The first CPU socket hosts the majority of the PCI devices on the system, including the network interfaces and the disks.

\subsection{NVIDIA DGX-1}
\label{sec:topology-dgx1}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth,draft]{../figures/explore-topo-dgx1.pdf}
    \caption[\todo{short}]{\todo{long}}
    \label{fig:actual-perf}
\end{figure}
